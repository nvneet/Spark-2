package com.sparksql;

import java.util.ArrayList;
import java.util.List;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.RowFactory;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.types.DataType;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.Metadata;
import org.apache.spark.sql.types.StructField;
import org.apache.spark.sql.types.StructType;

public class WithInMemoryData {

	public static void main(String[] args) {
		Logger.getLogger("org.apache").setLevel(Level.ERROR);
		
		SparkSession sparkSession = SparkSession.builder().appName("SparkSQL-App").master("local[*]").getOrCreate();
//		Dataset<Row> studentsData = sparkSession.read().option("header", true).csv("/root/sparkfiles/testdata/exams/students.csv");
//
//		studentsData.createOrReplaceTempView("students_view");
//		Dataset<Row> results = sparkSession.sql("select Distinct(year) from students_view order by year desc");

		List<Row> inMemoryData = new ArrayList<>();
		inMemoryData.add(RowFactory.create("Warn", "16 December 2018"));
		
		StructField[] fields = new StructField[] {
				new StructField("level", DataTypes.BooleanType, false, Metadata.empty()),
				new StructField("datetime", DataTypes.StringType, false, Metadata.empty())
		};
		
		StructType schema = new StructType();
		sparkSession.createDataFrame(inMemoryData, schema )
		
		results.show();		
		sparkSession.close();

	}

}
